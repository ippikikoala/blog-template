#!/usr/bin/env python3
"""
ã¯ã¦ãªãƒ–ãƒ­ã‚°ã®ç”»åƒã‚’ä¸€æ‹¬ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰

Usage:
    python3 scripts/download_images.py ippikikoala.hatenablog.com.export.txt
"""

import re
import requests
import os
import sys
from pathlib import Path
from urllib.parse import urlparse

def download_hatena_images(export_file, output_dir='hatena_images'):
    """ã¯ã¦ãªãƒ–ãƒ­ã‚°ã®ç”»åƒã‚’ä¸€æ‹¬ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""

    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    Path(output_dir).mkdir(parents=True, exist_ok=True)

    # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    print(f"ğŸ“– èª­ã¿è¾¼ã¿ä¸­: {export_file}")
    with open(export_file, 'r', encoding='utf-8') as f:
        content = f.read()

    # HTMLã®<img src>ã‹ã‚‰ç”»åƒURLã‚’æŠ½å‡º
    image_url_pattern = r'https://cdn-ak\.f\.st-hatena\.com/images/fotolife/[^"\s]+'
    all_urls = re.findall(image_url_pattern, content)

    # é‡è¤‡ã‚’å‰Šé™¤
    unique_urls = list(set(all_urls))
    print(f"ğŸ“Š {len(unique_urls)} å€‹ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªç”»åƒURLã‚’æ¤œå‡ºã—ã¾ã—ãŸ")

    downloaded = []
    failed = []

    for i, url in enumerate(unique_urls, 1):
        # URLã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æŠ½å‡º
        parsed_url = urlparse(url)
        filename = os.path.basename(parsed_url.path)
        filepath = os.path.join(output_dir, filename)

        # æ—¢ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãªã‚‰ã‚¹ã‚­ãƒƒãƒ—
        if os.path.exists(filepath):
            print(f"â­ï¸  [{i}/{len(unique_urls)}] ã‚¹ã‚­ãƒƒãƒ—: {filename} (æ—¢å­˜)")
            downloaded.append({
                'url': url,
                'filename': filename
            })
            continue

        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        try:
            print(f"â¬‡ï¸  [{i}/{len(unique_urls)}] ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­: {filename}")
            response = requests.get(url, timeout=30)
            if response.status_code == 200:
                with open(filepath, 'wb') as img_file:
                    img_file.write(response.content)
                size_kb = len(response.content) / 1024
                print(f"âœ… [{i}/{len(unique_urls)}] å®Œäº†: {filename} ({size_kb:.1f} KB)")
                downloaded.append({
                    'url': url,
                    'filename': filename
                })
            else:
                print(f"âŒ [{i}/{len(unique_urls)}] å¤±æ•—: {url} (Status: {response.status_code})")
                failed.append({'url': url, 'reason': f'HTTP {response.status_code}'})
        except Exception as e:
            print(f"âŒ [{i}/{len(unique_urls)}] ã‚¨ãƒ©ãƒ¼: {url} - {str(e)}")
            failed.append({'url': url, 'reason': str(e)})

    # ãƒãƒƒãƒ”ãƒ³ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
    mapping_file = os.path.join(output_dir, 'image_mapping.txt')
    with open(mapping_file, 'w', encoding='utf-8') as f:
        for item in downloaded:
            f.write(f"{item['url']}|{item['filename']}\n")

    print("\n" + "="*60)
    print(f"âœ… ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†: {len(downloaded)} æš")
    if failed:
        print(f"âŒ å¤±æ•—: {len(failed)} æš")
        print("\nå¤±æ•—ã—ãŸURL:")
        for item in failed:
            print(f"  - {item['url']} ({item['reason']})")
    print(f"\nğŸ“ ä¿å­˜å…ˆ: {output_dir}/")
    print(f"ğŸ“„ ãƒãƒƒãƒ”ãƒ³ã‚°ãƒ•ã‚¡ã‚¤ãƒ«: {mapping_file}")
    print("="*60)

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Usage: python3 download_images.py <export_file>")
        print("Example: python3 download_images.py ippikikoala.hatenablog.com.export.txt")
        sys.exit(1)

    export_file = sys.argv[1]

    if not os.path.exists(export_file):
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {export_file}")
        sys.exit(1)

    download_hatena_images(export_file)
