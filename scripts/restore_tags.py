#!/usr/bin/env python3
"""
ã¯ã¦ãªãƒ–ãƒ­ã‚°ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‹ã‚‰ã‚¿ã‚°ã‚’å¾©å…ƒã—ã¦MDXãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ä»¥ä¸‹ã®å‡¦ç†ã‚’è¡Œã„ã¾ã™:
1. ã¯ã¦ãªãƒ–ãƒ­ã‚°ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æ
2. å„è¨˜äº‹ã®BASENAMEã¨è¤‡æ•°ã®CATEGORYã‚’æŠ½å‡º
3. æœ€åˆã®CATEGORYã¯categoryã€2ã¤ç›®ä»¥é™ã¯tagsã¨ã—ã¦æ‰±ã†
4. å¯¾å¿œã™ã‚‹MDXãƒ•ã‚¡ã‚¤ãƒ«ã®frontmatterã‚’æ›´æ–°

Usage:
    python3 scripts/restore_tags.py <export_file>

Example:
    python3 scripts/restore_tags.py ippikikoala.hatenablog.com.export.txt

Output:
    - content/posts/*.mdx ãƒ•ã‚¡ã‚¤ãƒ«ã®tagsãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒæ›´æ–°ã•ã‚Œã¾ã™
"""

import re
import sys
import os
from pathlib import Path
from datetime import datetime


def parse_hatena_export(export_file):
    """ã¯ã¦ãªãƒ–ãƒ­ã‚°ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦ã‚¿ã‚°æƒ…å ±ã‚’æŠ½å‡º"""

    with open(export_file, 'r', encoding='utf-8') as f:
        content = f.read()

    # è¨˜äº‹ã”ã¨ã«åˆ†å‰²ï¼ˆ--------ã§åŒºåˆ‡ã‚‰ã‚Œã¦ã„ã‚‹ï¼‰
    entries = content.split('--------')

    posts = []

    for entry in entries:
        if not entry.strip():
            continue

        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’å–å¾—ï¼ˆæœ€åˆã®-----ã¾ã§ï¼‰
        if '-----' not in entry:
            continue

        metadata_section = entry.split('-----')[0]

        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‘ãƒ¼ã‚¹
        post = {'categories': []}
        for line in metadata_section.split('\n'):
            line = line.strip()
            if ':' in line:
                key, value = line.split(':', 1)
                key = key.strip().upper()
                value = value.strip()

                if key == 'CATEGORY':
                    post['categories'].append(value)
                elif key == 'BASENAME':
                    post['basename'] = value
                elif key == 'DATE':
                    post['date'] = value
                elif key == 'TITLE':
                    post['title'] = value

        if post.get('basename') and post.get('categories'):
            posts.append(post)

    return posts


def basename_to_slug(basename, date_str):
    """BASENAMEã¨æ—¥ä»˜ã‹ã‚‰MDXãƒ•ã‚¡ã‚¤ãƒ«åã®slugã‚’ç”Ÿæˆ"""
    # æ—¥ä»˜å¤‰æ›
    try:
        dt = datetime.strptime(date_str, '%m/%d/%Y %H:%M:%S')
        date = dt.strftime('%Y-%m-%d')
    except:
        date = '2025-01-01'

    # basenameã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    if basename:
        # basenameã« "/" ã‚„ãã®ä»–ã®ç‰¹æ®Šæ–‡å­—ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯ç½®æ›
        clean_basename = re.sub(r'[^a-z0-9]+', '-', basename.lower())
        # å…ˆé ­ãƒ»æœ«å°¾ã®ãƒã‚¤ãƒ•ãƒ³ã‚’å‰Šé™¤
        clean_basename = clean_basename.strip('-')
    else:
        clean_basename = 'untitled'

    return f"{date}-{clean_basename}"


def update_mdx_tags(mdx_path, tags):
    """MDXãƒ•ã‚¡ã‚¤ãƒ«ã®tagsãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æ›´æ–°"""

    with open(mdx_path, 'r', encoding='utf-8') as f:
        content = f.read()

    # frontmatterã‚’è§£æ
    if not content.startswith('---'):
        return False

    # frontmatterã®çµ‚ã‚ã‚Šã‚’è¦‹ã¤ã‘ã‚‹
    end_match = re.search(r'\n---\n', content[3:])
    if not end_match:
        return False

    frontmatter_end = end_match.start() + 3
    frontmatter = content[3:frontmatter_end]
    body = content[frontmatter_end + 4:]  # \n---\n ã®4æ–‡å­—åˆ†

    # tagsè¡Œã‚’æ›´æ–°
    tags_str = str(tags)  # Python list to string representation

    # æ—¢å­˜ã®tagsè¡Œã‚’ç½®æ›
    new_frontmatter = re.sub(
        r'^tags:.*$',
        f'tags: {tags_str}',
        frontmatter,
        flags=re.MULTILINE
    )

    # æ–°ã—ã„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ä½œæˆ
    new_content = f"---{new_frontmatter}\n---\n{body}"

    with open(mdx_path, 'w', encoding='utf-8') as f:
        f.write(new_content)

    return True


def find_mdx_file(posts_dir, slug):
    """slugã«ä¸€è‡´ã™ã‚‹MDXãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™"""
    # å®Œå…¨ä¸€è‡´
    exact_path = posts_dir / f"{slug}.mdx"
    if exact_path.exists():
        return exact_path

    # éƒ¨åˆ†ä¸€è‡´ï¼ˆæ—¥ä»˜éƒ¨åˆ†ã§æ¤œç´¢ï¼‰
    date_part = slug[:10]  # YYYY-MM-DD
    for mdx_file in posts_dir.glob(f"{date_part}*.mdx"):
        return mdx_file

    return None


def main():
    if len(sys.argv) < 2:
        print("Usage: python3 restore_tags.py <export_file>")
        print("Example: python3 restore_tags.py ippikikoala.hatenablog.com.export.txt")
        sys.exit(1)

    export_file = sys.argv[1]

    if not os.path.exists(export_file):
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {export_file}")
        sys.exit(1)

    posts_dir = Path('content/posts')
    if not posts_dir.exists():
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: content/postsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        sys.exit(1)

    print(f"ğŸ“– ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«: {export_file}")
    print()

    # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‘ãƒ¼ã‚¹
    print("ğŸ“„ è¨˜äº‹ã‚’è§£æä¸­...")
    posts = parse_hatena_export(export_file)
    print(f"âœ… {len(posts)} ä»¶ã®è¨˜äº‹ã‚’æ¤œå‡ºã—ã¾ã—ãŸ")
    print()

    # çµ±è¨ˆæƒ…å ±
    updated = 0
    not_found = 0
    no_tags = 0

    for post in posts:
        basename = post.get('basename', '')
        date_str = post.get('date', '')
        categories = post.get('categories', [])
        title = post.get('title', 'Untitled')

        # slugã‚’ç”Ÿæˆ
        slug = basename_to_slug(basename, date_str)

        # MDXãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
        mdx_file = find_mdx_file(posts_dir, slug)

        if not mdx_file:
            not_found += 1
            continue

        # ã‚¿ã‚°ã‚’æŠ½å‡ºï¼ˆ2ç•ªç›®ä»¥é™ã®CATEGORYï¼‰
        if len(categories) > 1:
            tags = categories[1:]
        else:
            tags = []
            no_tags += 1
            continue

        # MDXãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°
        if update_mdx_tags(mdx_file, tags):
            updated += 1
            print(f"âœ… æ›´æ–°: {mdx_file.name}")
            print(f"   ã‚¿ã‚°: {tags}")
        else:
            print(f"âš ï¸  æ›´æ–°å¤±æ•—: {mdx_file.name}")

    print("\n" + "="*60)
    print(f"âœ… æ›´æ–°å®Œäº†: {updated} ä»¶")
    print(f"âš ï¸  ã‚¿ã‚°ãªã—: {no_tags} ä»¶")
    print(f"âŒ MDXæœªç™ºè¦‹: {not_found} ä»¶")
    print("="*60)


if __name__ == "__main__":
    main()
